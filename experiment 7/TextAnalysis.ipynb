{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cdf1eca-2517-42b3-bf11-735e7c7bc82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8b2f95e-46bb-4f4a-8306-539d32406337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Document\n",
    "document = \"\"\"Natural Language Processing (NLP) is a sub-field of Artificial Intelligence (AI) that deals with the interaction \n",
    "between computers and human language. It involves various tasks such as text analysis, speech recognition, and machine translation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01377e5a-9a5e-4cb5-b342-ba4fa7737421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Words: ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'sub-field', 'of', 'Artificial', 'Intelligence', '(', 'AI', ')', 'that', 'deals', 'with', 'the', 'interaction', 'between', 'computers', 'and', 'human', 'language', '.', 'It', 'involves', 'various', 'tasks', 'such', 'as', 'text', 'analysis', ',', 'speech', 'recognition', ',', 'and', 'machine', 'translation', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokens = word_tokenize(document)\n",
    "print(\"Tokenized Words:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ce5a455-f8a6-4682-bbd1-dd91155db00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "POS Tags: [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('a', 'DT'), ('sub-field', 'NN'), ('of', 'IN'), ('Artificial', 'JJ'), ('Intelligence', 'NNP'), ('(', '('), ('AI', 'NNP'), (')', ')'), ('that', 'IN'), ('deals', 'NNS'), ('with', 'IN'), ('the', 'DT'), ('interaction', 'NN'), ('between', 'IN'), ('computers', 'NNS'), ('and', 'CC'), ('human', 'JJ'), ('language', 'NN'), ('.', '.'), ('It', 'PRP'), ('involves', 'VBZ'), ('various', 'JJ'), ('tasks', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('text', 'JJ'), ('analysis', 'NN'), (',', ','), ('speech', 'NN'), ('recognition', 'NN'), (',', ','), ('and', 'CC'), ('machine', 'NN'), ('translation', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# POS Tagging\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "print(\"\\nPOS Tags:\", pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "324422db-649a-49de-82b6-4508915310fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Tokens (Stopwords Removed): ['Natural', 'Language', 'Processing', 'NLP', 'sub-field', 'Artificial', 'Intelligence', 'AI', 'deals', 'interaction', 'computers', 'human', 'language', 'involves', 'various', 'tasks', 'text', 'analysis', 'speech', 'recognition', 'machine', 'translation']\n"
     ]
    }
   ],
   "source": [
    "# Stopwords Removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words and word not in string.punctuation]\n",
    "print(\"\\nFiltered Tokens (Stopwords Removed):\", filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64bea6b2-eea7-47cf-949d-bfb3319004c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stemmed Tokens: ['natur', 'languag', 'process', 'nlp', 'sub-field', 'artifici', 'intellig', 'ai', 'deal', 'interact', 'comput', 'human', 'languag', 'involv', 'variou', 'task', 'text', 'analysi', 'speech', 'recognit', 'machin', 'translat']\n"
     ]
    }
   ],
   "source": [
    "# Stemming (using Porter Stemmer)\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "print(\"\\nStemmed Tokens:\", stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c310e98-ab4d-4a93-bfe2-25f9a44646c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmatized Tokens: ['Natural', 'Language', 'Processing', 'NLP', 'sub-field', 'Artificial', 'Intelligence', 'AI', 'deal', 'interaction', 'computer', 'human', 'language', 'involves', 'various', 'task', 'text', 'analysis', 'speech', 'recognition', 'machine', 'translation']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization (using WordNet Lemmatizer)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "print(\"\\nLemmatized Tokens:\", lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cbbeaff-e653-4146-ab1b-d140532ca61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Term Frequency (TF):\n",
      "Natural: 1\n",
      "Language: 1\n",
      "Processing: 1\n",
      "NLP: 1\n",
      "sub-field: 1\n",
      "Artificial: 1\n",
      "Intelligence: 1\n",
      "AI: 1\n",
      "deals: 1\n",
      "interaction: 1\n",
      "computers: 1\n",
      "human: 1\n",
      "language: 1\n",
      "involves: 1\n",
      "various: 1\n",
      "tasks: 1\n",
      "text: 1\n",
      "analysis: 1\n",
      "speech: 1\n",
      "recognition: 1\n",
      "machine: 1\n",
      "translation: 1\n"
     ]
    }
   ],
   "source": [
    "# Term Frequency (TF)\n",
    "fdist = FreqDist(filtered_tokens)\n",
    "print(\"\\nTerm Frequency (TF):\")\n",
    "for word, freq in fdist.items():\n",
    "    print(f\"{word}: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98fc977f-ae91-4c30-8c10-94c205a9a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse Document Frequency (IDF)\n",
    "# For IDF calculation, let's assume a small corpus with multiple documents.\n",
    "# We will use a dummy corpus of 3 documents.\n",
    "corpus = [\n",
    "    \"Natural Language Processing is a field of study.\",\n",
    "    \"NLP and AI are related fields.\",\n",
    "    \"Text analysis is a key task in NLP.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c45e749a-5ea5-47a9-b322-81b8817805c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Matrix:\n",
      "[[0.         0.         0.4472136  0.         0.         0.4472136\n",
      "  0.4472136  0.         0.4472136  0.         0.4472136  0.\n",
      "  0.        ]\n",
      " [0.52863461 0.         0.         0.52863461 0.         0.\n",
      "  0.         0.40204024 0.         0.52863461 0.         0.\n",
      "  0.        ]\n",
      " [0.         0.46735098 0.         0.         0.46735098 0.\n",
      "  0.         0.35543247 0.         0.         0.         0.46735098\n",
      "  0.46735098]]\n",
      "\n",
      "Feature Names (Words in the Corpus):\n",
      "['ai' 'analysis' 'field' 'fields' 'key' 'language' 'natural' 'nlp'\n",
      " 'processing' 'related' 'study' 'task' 'text']\n"
     ]
    }
   ],
   "source": [
    "# Create TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Show the TF-IDF values for the words in the document\n",
    "print(\"\\nTF-IDF Matrix:\")\n",
    "print(tfidf_matrix.toarray())\n",
    "\n",
    "# Get the feature names (words in the vocabulary)\n",
    "print(\"\\nFeature Names (Words in the Corpus):\")\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a1044c-88b7-49d9-8c43-997b596788e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
